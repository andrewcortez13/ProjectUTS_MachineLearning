# -*- coding: utf-8 -*-
"""Copy of TugasML(5)_ChessGame_NaiveBayes

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10lNVbM2ZzMTTgOLkNkaaH-rhsC8K17Gu
"""

# Referensi : https://towardsdatascience.com/naive-bayes-classifier-how-to-successfully-use-it-in-python-ecf76a995069

# Untuk mengambil data dari google drive
from google.colab import drive 
drive.mount('/content/gdrive')

# Library yang akan digunakan
import pandas as pd # for data manipulation
import numpy as np # for data manipulation

from sklearn.model_selection import train_test_split # for splitting the data into train and test samples
from sklearn.metrics import classification_report # for model evaluation metrics
from sklearn.preprocessing import OrdinalEncoder # for encoding categorical features from strings to number arrays

import plotly.express as px  # for data visualization
import plotly.graph_objects as go # for data visualization

# Differnt types of Naive Bayes Classifiers
from sklearn.naive_bayes import GaussianNB
from sklearn.naive_bayes import CategoricalNB
from sklearn.naive_bayes import BernoulliNB
from sklearn.naive_bayes import MultinomialNB

# Data yang akan digunakan didapat dari : https://www.kaggle.com/datasnaek/chess
# Data saya masukkan ke google drive saya, di folder csv_file dengan nama data games.csv

# Read data dari google drive, dimasukkan ke variable df
df=pd.read_csv('/content/gdrive/My Drive/csv_file/games.csv', encoding='utf-8')
# Mengeprint beberapa column, disini ada 12 jenis sample table yang akan di print
df.iloc[:,:12]

# Mengecek data data dari column winner, resultnya ada apa aja, dan jumlahnya berapa, dari data, kita dapat melihat putih lebih sering menang daripada hitam, namun hasilnya lumayan seimbang
# Dengan total kemenangan 10001 dari white, 9107 dari  black, dan draw 950
df['winner'].value_counts()

# Training Data, dengan membuat beberapa bidang yang akan digunakan di model

# Mencari perbedaan white rating dengan black rating - independent variable
# Yang merupakan variable yang akan mempengaruhi data
df['rating_difference']=df['white_rating']-df['black_rating']

# Memberikan flag untuk siapa yang menang kalo white_wins = 1, lainnya 0 (black wins/draw) - dependent (target) variable
# Dependent variable yang akan diukur dan dicari, dari data karena ada perubahaan variabel independent
df['white_win']=df['winner'].apply(lambda x: 1 if x=='white' else 0)

# Match outcome, hasil dari match, di kasi label : 
#1 : Jika white wins, 0 : Draw, -1 : Jika black wins
#digunakan untuk regresi multinomial, variable dependent
df['match_outcome']=df['winner'].apply(lambda x: 1 if x=='white' else 
                                       0 if x=='draw' else -1)
# Mengecek data yang kita buat, dengan print beberapa column di dataframe
df.iloc[:,13:]

# Function that handles sample splitting, model fitting and report printing 
def mfunc(X, y, typ):
    
    # Membuat sample training, dan testing
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

    # Men- fitkan model
    model = typ
    clf = model.fit(X_train, y_train)

    # Memprediksi label kelas pada test data
    pred_labels = model.predict(X_test)

    # Print model attributes 
    print('Classes: ', clf.classes_) # Label class yang diketahui classifier

    if str(typ)== "GaussianNB(priors=None, var_smoothing=1e-09)" :
        print('Class Priors: ',clf.class_prior_) #  Probabilitas sebelumnya daripada setiap kelas
    else: 
        print('Class Log Priors: ',clf.class_log_prior_) # log prior probability of each class.
       
    # Menggunakan metode skor untuk mendapatkan seberapa akurasi model
    print('--------------------------------------------------------')
    score = model.score(X_test, y_test)
    print('Accuracy Score: ', score)
    print('--------------------------------------------------------')
    
    # Melihat laporan clasifikasi untuk evaluasi model
    print(classification_report(y_test, pred_labels))
    
    # Data di return untuk plot graphic
    return X_train, X_test, y_train, y_test, clf, pred_labels

# 1)Gaussian NB with 2 independent variables

# Select data for modeling
X=df[['rating_difference', 'turns']]
y=df['white_win'].values

# Fit the model and print the result
X_train, X_test, y_train, y_test, clf, pred_labels, = mfunc(X, y, GaussianNB())

# Akurasi = Melihat akurasi dari data 
# Presicion = True Positive/ (True Positive + False Positive), Lower presisi berarti lebih besar number false positive

# Recall = True Positive/(True Positive + False Negative), Low recall berarti model mengandung
# banyak false negative, itu tidak bisa prediksi banyak proporsi dari class member

# F-1 Sscore = Rata-rata dari precision dan recall (Weight dapat applied jika satu metrics, lebih penting)
# Daripada yang lain dalam kasus penggunaan tertentu

# Dari data, kita dapat predisksi putih menang/tidak di 66% kemungkinan kasus, lebih baik daripada random guess, 50% kemungkinan benar
# Disini kita menggunkan variable turn, tapi tidak bisa digunakan di dunia nyata, karena turn tidak diketahui waktu pertandingan belum selesai

# Karena menggunakan 2 variabel independen (prediktor), dapat dengan mudah divisualisasikan dengan grafik
# Specify a size of the mesh to be used
mesh_size = 5
margin = 1

# Membuat grid mesh, dimana run code
x_min, x_max = X.iloc[:, 0].fillna(X.mean()).min() - margin, X.iloc[:, 0].fillna(X.mean()).max() + margin
y_min, y_max = X.iloc[:, 1].fillna(X.mean()).min() - margin, X.iloc[:, 1].fillna(X.mean()).max() + margin
xrange = np.arange(x_min, x_max, mesh_size)
yrange = np.arange(y_min, y_max, mesh_size)
xx, yy = np.meshgrid(xrange, yrange)

# Membuat pengklasifikasi, menjalankan prediksi di grid
Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]
Z = Z.reshape(xx.shape)

# Menspesifikasikan jejak
trace_specs = [
    #[X_train, y_train, 0, 'Train', 'brown'],
    #[X_train, y_train, 1, 'Train', 'aqua'],
    [X_test, y_test, 0, 'Test', 'red'],
    [X_test, y_test, 1, 'Test', 'blue']
]

# Membuat grafik dengan trace_specs diatas
fig = go.Figure(data=[
    go.Scatter(
        x=X[y==label].iloc[:, 0], y=X[y==label].iloc[:, 1],
        name=f'{split} data, Actual Class: {label}',
        mode='markers', marker_color=marker
    )
    for X, y, label, split, marker in trace_specs
])

# Mnegudpate marker size
fig.update_traces(marker_size=2, marker_line_width=0)

# Update axis range
fig.update_xaxes(range=[-1600, 1500])
fig.update_yaxes(range=[0,345])

# Update chart, dan legend placement
fig.update_layout(title_text="Decision Boundary for Naive Bayes Model", 
    legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1))

# Menambahkan contour graph
fig.add_trace(
    go.Contour(
        x=xrange,
        y=yrange,
        z=Z,
        showscale=True,
        colorscale='magma',
        opacity=1,
        name='Score',
        hoverinfo='skip'
    )
)

fig.show()

# 2) Gaussian NB with 3 class labels and 2 independent variables

# Mengganti target ke match_outcome

X=df[['rating_difference', 'turns']]
y=df['match_outcome'].values

# Fit model, dan print resultnya
X_train, X_test, y_train, y_test, clf, pred_labels = mfunc(X, y, GaussianNB())

# Dari data, model kesulitan prediksi class =0, yang merupakan draw, dikarenakan
# Sedikitnya sample number observation tersedia di dalam class ini(175 dari test sample)
# Dari data support class 0, karenanya presisi dan recall sangat kecil, 0.18 dan 0.07

# Ketika data tidak balance, kita dapat melakukan hal-hal untuk mengatasinya, dengan salah satu cara 
# Oversample minority class, disini class = 0 (draw)

# 3) Categorical NB with 2 independent variables

# Menggunakan categorical independent variable
# Opening_eco : Opening yang digunakan
# White_id    : ID Player yang memainkan warna putih


# Select data for modeling
X=df[['opening_eco', 'white_id']]
y=df['white_win'].values

# Encode categorical variables
enc = OrdinalEncoder()
X = enc.fit_transform(X)

# Fit the model and print the result
X_train, X_test, y_train, y_test, clf, pred_labels = mfunc2(X, y, CategoricalNB())

# akurasi model 0.6, lebih buruk daripada Gaussian, tapi dapat diimpprove dengan 
# combine continous dan categorical variable menjadi 1 model

# 4) Bernoulli NB with 1 independent variable

# Bernoulli NB digunakan ketika kita mempunyai binary predictor, disini kita menggunakan
# rated, dimana untuk melihat rated/tidak

# Select data for modeling
X=df['rated'].values.reshape(-1,1)
y=df['white_win'].values

# Fit the model and print the result
X_train, X_test, y_train, y_test, clf, pred_labels = mfunc(X, y, BernoulliNB())

# Dapat dilihat dari match Rated/tidak, tidak mempengaruhi hasil dari match
# Model akurasi dan presisi sama sama 0.50, yang berarti modelnya sama 
# bagusnya dengan random guess (50-50)

# 5) Mixed NB (Gaussian + Categorical) approach 1

# Membuang isi variable (ratting_difference, turns)menjadi 20% kuantil
df['rating_difference_qt'] = pd.qcut(df['rating_difference'], 5, labels=['bottom 20', 'lower 20', 'middle 20', 'upper 20', 'top 20'])
df['turns_qt'] = pd.qcut(df['turns'], 5, labels=['bottom 20', 'lower 20', 'middle 20', 'upper 20', 'top 20'])

# Data-data yang digunakan untuk modeling
X=df[['opening_eco', 'white_id', 'rating_difference_qt', 'turns_qt']]
y=df['white_win'].values

# Encode variable kategoris
enc = OrdinalEncoder()
X = enc.fit_transform(X)

# Mengefitkan dengan model, dan print hasilnya
X_train, X_test, y_train, y_test, clf, pred_labels = mfunc(X, y, CategoricalNB())

# Dengan ini, kita membuat model yang paling bagus dengan akurasi lebih dari 65%

# 6) Mixed NB (Gaussian + Categorical) approach 2

# Disini, kita melatih 2 model terpisah dengan 2 variable independent kontinue dan kategoris.
# Kemudain kita akan mengambil probabilitas prediksi dari kedua model untuk train data model.


# Prepare data
# Memilih data yang digunakan untuk modelling
X_G=df[['rating_difference', 'turns']] # Gaussian, i.e. continuous
X_C=df[['opening_eco', 'white_id']] # Categorical, i.e. discrete
y=df['white_win'].values

# Encode variable categorical
enc = OrdinalEncoder()
X_C = enc.fit_transform(X_C)

# Menggabungkan variable menjadi 1 array
X=np.c_[X_G, X_C[:,0].ravel(), X_C[:,1].ravel()]

# Membuat training dan testing sample
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)


# Fit kedua model
# Menggunakan Gaussian untuk continous indepedent variable
model_G = GaussianNB()
clf_G = model_G.fit(X_train[:,0:2], y_train)
# Menggunakan categorical untuk discrete independent variable
model_C = CategoricalNB()
clf_C = model_C.fit(X_train[:,2:4], y_train)


# Mengambil probabilitas dari kedua model
# Di training data
G_train_probas = model_G.predict_proba(X_train[:,0:2])
C_train_probas = model_C.predict_proba(X_train[:,2:4])
# Di testing data
G_test_probas = model_G.predict_proba(X_test[:,0:2])
C_test_probas = model_C.predict_proba(X_test[:,2:4])

# Menggabungkan prediksi probabilitas untuk kelas=1, menjadi array 2D
X_new_train = np.c_[(G_train_probas[:,1], C_train_probas[:,1])] # Train
X_new_test = np.c_[(G_test_probas[:,1], C_test_probas[:,1])] # Test


# Fit Gaussian model ke X_new
model = GaussianNB()
clf = model.fit(X_new_train, y_train)

# Memprediksi class label di test data
pred_labels = model.predict(X_new_test)


# Print Result
print('Classes: ', clf.classes_) # Class label yang diketahui classifier
print('Class Priors: ',clf.class_prior_) # Probabilitas dari setiap class
# Menggunakan score method untuk mengetahui akurasi model
print('--------------------------------------------------------')
score = model.score(X_new_test, y_test)
print('Accuracy Score: ', score)
print('--------------------------------------------------------')
# Untuk melihat classification report untuk evaluasi model
print(classification_report(y_test, pred_labels))

# Disini, kita dapat melihat algoritma Naive Bayes, sangat fleksibel dan cepat, 
# Dan, bekerja lumayan baik di beberapa situasi
